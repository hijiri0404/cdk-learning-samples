"""
ğŸ”§ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†Lambdaé–¢æ•°

S3ã‚¤ãƒ™ãƒ³ãƒˆã‚’ãƒˆãƒªã‚¬ãƒ¼ã¨ã—ã¦å®Ÿè¡Œã•ã‚Œã‚‹ã€ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å°‚ç”¨ã®Lambdaé–¢æ•°ã§ã™ã€‚
ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼ã€å¤‰æ›ã€ç§»å‹•ãªã©ã‚’è‡ªå‹•å®Ÿè¡Œã—ã¾ã™ã€‚
"""

import json
import boto3
import os
from urllib.parse import unquote_plus
from typing import Dict, Any
import logging

# ãƒ­ã‚°è¨­å®š
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# AWS ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
s3_client = boto3.client('s3')

# ç’°å¢ƒå¤‰æ•°å–å¾—
UPLOAD_BUCKET = os.environ['UPLOAD_BUCKET']
PROCESSED_BUCKET = os.environ['PROCESSED_BUCKET']
MAX_FILE_SIZE_MB = int(os.environ.get('MAX_FILE_SIZE_MB', '10'))
ALLOWED_FILE_TYPES = os.environ.get('ALLOWED_FILE_TYPES', '.jpg,.png,.pdf').split(',')
ENABLE_VIRUS_SCAN = os.environ.get('ENABLE_VIRUS_SCAN', 'false').lower() == 'true'
ENABLE_IMAGE_RESIZE = os.environ.get('ENABLE_IMAGE_RESIZE', 'true').lower() == 'true'


def lambda_handler(event: Dict[str, Any], context: Any) -> Dict[str, Any]:
    """
    S3ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†ã®ãƒ¡ã‚¤ãƒ³ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
    """
    try:
        # S3ã‚¤ãƒ™ãƒ³ãƒˆã®è§£æ
        for record in event['Records']:
            if record['eventSource'] == 'aws:s3':
                process_s3_event(record)
        
        return {'statusCode': 200, 'body': 'Successfully processed files'}
        
    except Exception as e:
        logger.error(f"Error processing event: {str(e)}")
        raise


def process_s3_event(record: Dict[str, Any]) -> None:
    """
    S3ã‚¤ãƒ™ãƒ³ãƒˆãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å‡¦ç†
    """
    bucket_name = record['s3']['bucket']['name']
    object_key = unquote_plus(record['s3']['object']['key'])
    event_name = record['eventName']
    
    logger.info(f"Processing {event_name} for {bucket_name}/{object_key}")
    
    if event_name.startswith('ObjectCreated'):
        process_uploaded_file(bucket_name, object_key)
    elif event_name.startswith('ObjectRemoved'):
        logger.info(f"File removed: {object_key}")


def process_uploaded_file(bucket_name: str, object_key: str) -> None:
    """
    ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
    """
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±å–å¾—
        response = s3_client.head_object(Bucket=bucket_name, Key=object_key)
        file_size = response['ContentLength']
        content_type = response.get('ContentType', '')
        
        logger.info(f"File info: size={file_size}, type={content_type}")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
        if not validate_file(object_key, file_size, content_type):
            move_to_quarantine(bucket_name, object_key, "Validation failed")
            return
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å®Ÿè¡Œ
        if content_type.startswith('image/') and ENABLE_IMAGE_RESIZE:
            process_image(bucket_name, object_key)
        else:
            move_to_processed(bucket_name, object_key)
            
    except Exception as e:
        logger.error(f"Error processing file {object_key}: {str(e)}")
        move_to_quarantine(bucket_name, object_key, f"Processing error: {str(e)}")


def validate_file(object_key: str, file_size: int, content_type: str) -> bool:
    """
    ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
    """
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
    max_size_bytes = MAX_FILE_SIZE_MB * 1024 * 1024
    if file_size > max_size_bytes:
        logger.warning(f"File too large: {file_size} bytes (max: {max_size_bytes})")
        return False
    
    # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ãƒã‚§ãƒƒã‚¯
    file_extension = os.path.splitext(object_key)[1].lower()
    if file_extension not in ALLOWED_FILE_TYPES:
        logger.warning(f"Invalid file type: {file_extension}")
        return False
    
    logger.info("File validation passed")
    return True


def process_image(bucket_name: str, object_key: str) -> None:
    """
    ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ï¼ˆãƒªã‚µã‚¤ã‚ºç­‰ï¼‰
    """
    try:
        # åŸºæœ¬çš„ãªç”»åƒå‡¦ç†ï¼ˆã“ã®ä¾‹ã§ã¯å˜ç´”ã«ã‚³ãƒ”ãƒ¼ï¼‰
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ PIL/Pillow ã‚„ Sharp ã‚’ä½¿ç”¨
        
        processed_key = f"processed/{object_key}"
        
        # å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        response = s3_client.get_object(Bucket=bucket_name, Key=object_key)
        file_content = response['Body'].read()
        
        # å‡¦ç†æ¸ˆã¿ãƒã‚±ãƒƒãƒˆã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        s3_client.put_object(
            Bucket=PROCESSED_BUCKET,
            Key=processed_key,
            Body=file_content,
            ContentType=response.get('ContentType', 'application/octet-stream'),
            Metadata={
                'original-key': object_key,
                'processed-by': 'file-upload-system',
                'processing-status': 'completed'
            }
        )
        
        logger.info(f"Image processed: {object_key} -> {processed_key}")
        
        # å…ƒãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        s3_client.delete_object(Bucket=bucket_name, Key=object_key)
        
    except Exception as e:
        logger.error(f"Error processing image {object_key}: {str(e)}")
        raise


def move_to_processed(bucket_name: str, object_key: str) -> None:
    """
    å‡¦ç†æ¸ˆã¿ãƒã‚±ãƒƒãƒˆã«ç§»å‹•
    """
    try:
        processed_key = f"processed/{object_key}"
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
        s3_client.copy_object(
            CopySource={'Bucket': bucket_name, 'Key': object_key},
            Bucket=PROCESSED_BUCKET,
            Key=processed_key,
            MetadataDirective='REPLACE',
            Metadata={
                'original-key': object_key,
                'processed-by': 'file-upload-system',
                'processing-status': 'completed'
            }
        )
        
        # å…ƒãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        s3_client.delete_object(Bucket=bucket_name, Key=object_key)
        
        logger.info(f"File moved to processed: {object_key}")
        
    except Exception as e:
        logger.error(f"Error moving file {object_key}: {str(e)}")
        raise


def move_to_quarantine(bucket_name: str, object_key: str, reason: str) -> None:
    """
    éš”é›¢ãƒ•ã‚©ãƒ«ãƒ€ã«ç§»å‹•
    """
    try:
        quarantine_key = f"quarantine/{object_key}"
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
        s3_client.copy_object(
            CopySource={'Bucket': bucket_name, 'Key': object_key},
            Bucket=bucket_name,
            Key=quarantine_key,
            MetadataDirective='REPLACE',
            Metadata={
                'quarantine-reason': reason,
                'original-key': object_key,
                'quarantined-by': 'file-upload-system'
            }
        )
        
        # å…ƒãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        s3_client.delete_object(Bucket=bucket_name, Key=object_key)
        
        logger.warning(f"File quarantined: {object_key} (reason: {reason})")
        
    except Exception as e:
        logger.error(f"Error quarantining file {object_key}: {str(e)}")
        raise